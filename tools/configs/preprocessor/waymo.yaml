defaults:
  - base_cfg
  - _self_

name: waymo
class_names: ['Vehicle', 'Pedestrian', 'Cyclist']
pseudo_label_tag: 'vilgod_waymo'

clustering:
  model:
    _target_: hdbscan.HDBSCAN
    cluster_selection_epsilon: 0.15
    min_cluster_size: 15 # 5 -> the larger the stricter (less clusters)
    metric: euclidean
    core_dist_n_jobs: -1
  filters_active: 
    - filter_by_number_points
    - filter_by_plane_distance
    - filter_by_height
  filters: 
    - name: filter_by_number_points
      args: 
        logic: and
        required: True
        min_points: 10
    - name: filter_by_height
      args: 
        logic: and
        required: True
        min_height: 0.3
        max_height: 6
    - name: filter_by_aspect_ratio
      args: 
        min_aspect_ratio: 1.0
        max_aspect_ratio: 5.0
    - name: filter_by_volume
      args: 
        logic: and
        min_volume: 0.5
    - name: filter_by_area
      args: 
        logic: and
        min_area: 0.35
    - name: filter_by_plane_distance
      args: 
        logic: and
        required: True
        max_min_height: 1.0
        min_max_height: 0.5
    - name: filter_by_density
      args: 
        min_density: 0.1
        max_density: 10
    - name: filter_by_ephemeral_score
      args: 
        logic: or
        percentile: 20
        min_percentile_pp_score: 0.7

  entropy_score_filter:
    percentile: 30
    min_percentile_pp_score: 0.5
  propability_threshold: 0.3

tracking:
  cluster:
    mode: cluster_center
    assignment: 
      method: assign_detections_greedy
      max_distance: 1.0
    min_length: 5
    max_missed: 3
    min_distance_dynamic: 2.0

lidar_image_projection:
    depth_bias: 0.2
    obj_ratio: 0.8
    bg_clr: 0.0
    resolution: 112
    depth: 8
    maxpool:
        _target_: torch.nn.MaxPool3d
        kernel_size: ${as_tuple:1, 5, 5}
        stride: 1
        padding: ${as_tuple:0, 1, 1}
    conv3d:
        _target_: torch.nn.Conv3d
        in_channels: 1
        out_channels: 1
        kernel_size: ${as_tuple:1, 3, 3}
        stride: 1
        padding: ${as_tuple:0, 1, 1}
        bias: True
    gaussian_kernel:
        sigma: 3
        zsigma: 1
    views:
        rotation:
            - x: [0, -10]
            - y: [0, -30, 30]
            - z: [0]
        translation: [-0.5, -0.5, 0]

clip:
    name: clip
    model_name: ViT-B-16.pt
    format: .png
    top_k: 1
    split_size: 50
    prompt_template: a point representation of a {}
    class_list: ['car', 'truck', 'bus', 'van', 'minivan', 'pickup truck', 'school bus', 'fire truck', 'ambulance', 
                 'pedestrian', 'human body', 'human',
                 'cyclist', 'rider', 'bicycle', 'bike',  
                 'traffic light', 'traffic sign', 'fence', 'pole',  'clutter', 'tree', 'house', 'wall']

    class_mapping:
        car: Vehicle
        truck: Vehicle
        bus: Vehicle
        van: Vehicle
        minivan: Vehicle
        pickup truck: Vehicle
        school bus: Vehicle
        fire truck: Vehicle
        ambulance: Vehicle
        pedestrian: Pedestrian
        human body: Pedestrian
        human: Pedestrian
        cyclist: Cyclist
        rider: Cyclist
        bicycle: Cyclist
        bike: Cyclist
        traffic light: Background
        traffic sign: Background
        fence: Background
        pole: Background
        clutter: Background
        tree: Background
        house: Background
        wall: Background